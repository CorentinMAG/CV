{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML4CV_5_convolutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CorentinMAG/CV/blob/main/ML4CV_5_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z8CT4B59o1w"
      },
      "source": [
        "We start with our usual imports and figure adjustments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOAjHCTz9byv"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from timeit import default_timer as timer\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16.0, 12.0)\n",
        "plt.rcParams['font.size'] = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z104vU69zXt"
      },
      "source": [
        "Then we load CIFAR10, and we create the usual `Dataset`s and `DataLoader`s.\n",
        "\n",
        "This time, though, we do **NOT** flatten the images (notice we do not add the `LambdaTransform` that was reshaping them to the list of transforms that are applied to the data). Instead, we use another `Transfomation` to normalize them, by subtracting the mean and dividing by the standard deviation of each channel. Here we simply assume they are both 0.5, you can modify this code to estimate them on CIFAR-10 and use the estimated values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGwm_Ifv9yrT",
        "outputId": "89baaea2-5fdf-4322-ee0b-c9afedd2a0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tsfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])]) \n",
        "train_ds = torchvision.datasets.CIFAR10(root=\"/data/\", train=True, transform=tsfms, download=True)\n",
        "test_ds = torchvision.datasets.CIFAR10(root=\"/data/\", train=False, transform=tsfms)\n",
        "\n",
        "classes = train_ds.classes\n",
        "n_classes = len(classes)\n",
        "input_side = train_ds[0][0].shape[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRwcf8Hy941l"
      },
      "source": [
        "splitted_datasets = torch.utils.data.random_split(train_ds, [45000, 5000])\n",
        "actual_train_subds = splitted_datasets[0]\n",
        "valid_subds = splitted_datasets[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFrzmtS_9619"
      },
      "source": [
        "small_actual_train_subds = torch.utils.data.Subset(actual_train_subds, range(500))\n",
        "small_valid_subds = torch.utils.data.Subset(valid_subds, range(100))\n",
        "small_test_subds = torch.utils.data.Subset(test_ds, range(100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK9zguSaBKy_"
      },
      "source": [
        "Note there is a difference with respect to our usual DataLoader creation: we double the batch size for the validation and test sets. Since they will be run with `torch.no_grad()` and will not compute gradients, they require less memory, and therefore we can use larger batch sizes when evaluating models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoeSlhyr98l-"
      },
      "source": [
        "batch_size = 128\n",
        "small_actual_train_dl = torch.utils.data.DataLoader(small_actual_train_subds, batch_size=batch_size, shuffle=True)\n",
        "small_valid_dl = torch.utils.data.DataLoader(small_valid_subds, batch_size=2*batch_size)\n",
        "small_test_dl = torch.utils.data.DataLoader(small_test_subds, batch_size=2*batch_size)\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
        "actual_train_dl = torch.utils.data.DataLoader(actual_train_subds, batch_size=batch_size)\n",
        "valid_dl = torch.utils.data.DataLoader(valid_subds, batch_size=2*batch_size)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=2*batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT4lgmNITwjp"
      },
      "source": [
        "Since we start to have several layers with a respectable number of parameters, it is time to move our training on the GPU. \n",
        "\n",
        "You should change runtime type, by selecting GPU in the menu `Runtime`->`Change runtime type`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiZ-UBLPwgMQ",
        "outputId": "48bea773-6bf8-4856-a360-3136fb795226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# This should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfCqaT_Y-A79"
      },
      "source": [
        "Now we define our first CNN. Similarly to the FC case, we create a variable architecture to experiment with a number of choices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFGreAAZ-BHd"
      },
      "source": [
        "def Conv2dReLUPool(in_channels, out_channels, kernel_size, stride, batch_norm=True, pooling=True):\n",
        "  layers = [\n",
        "    torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=(kernel_size-1)//2)\n",
        "  ]\n",
        "\n",
        "  if batch_norm:\n",
        "    layers.append(torch.nn.BatchNorm2d(out_channels))\n",
        "\n",
        "  layers.append(torch.nn.ReLU(inplace=True))\n",
        "\n",
        "  if pooling:\n",
        "    layers.append(torch.nn.MaxPool2d(2,2))\n",
        "\n",
        "  return torch.nn.Sequential(*layers)\n",
        "\n",
        "def LinearReLU(in_features, out_features, batch_norm=True):\n",
        "  layers = [\n",
        "    torch.nn.Linear(in_features, out_features)\n",
        "  ]\n",
        "\n",
        "  if batch_norm:\n",
        "    layers.append(torch.nn.BatchNorm1d(out_features));\n",
        "\n",
        "  layers.append(torch.nn.ReLU(inplace=True))\n",
        "\n",
        "  return torch.nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class VanillaCNN(torch.nn.Module):\n",
        "  def __init__(self, input_side, hidden_width, n_classes, n_additional_convs=0, use_batch_norm=True):\n",
        "    super(VanillaCNN, self).__init__()\n",
        "    self.first_conv = Conv2dReLUPool(3, 16, 5, 1, use_batch_norm, pooling=False)\n",
        "    self.additional_convs =  torch.nn.ModuleList(\n",
        "        [Conv2dReLUPool(2 ** (i+4), 2 ** (i+5), 3, 1, use_batch_norm, pooling=i<3) for i in range(n_additional_convs)])\n",
        "    n_features = 2**(n_additional_convs+4) * ((input_side//(2**(min(n_additional_convs,3))))**2)\n",
        "    self.first_fc = LinearReLU(n_features, hidden_width, use_batch_norm) \n",
        "    self.second_fc = LinearReLU(hidden_width, hidden_width, use_batch_norm) \n",
        "    self.third_fc = torch.nn.Linear(hidden_width, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.first_conv(x)\n",
        "    for layer in self.additional_convs:\n",
        "      x = layer(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = self.first_fc(x)\n",
        "    x = self.second_fc(x)\n",
        "    x = self.third_fc(x)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRc1z9ie0yJe"
      },
      "source": [
        "One way to get an overview of the number and kind of layers in a `torch.nn.Module` is by using the `torchsummary` package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcQjcDKP0nrR",
        "outputId": "a766c52e-9308-4b01-caf0-f9cf12785357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "cnn = VanillaCNN(input_side, 128, n_classes, 4, True)\n",
        "import torchsummary\n",
        "torchsummary.summary(cnn, (3,32,32), batch_size=128, device=\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [128, 16, 32, 32]           1,216\n",
            "       BatchNorm2d-2          [128, 16, 32, 32]              32\n",
            "              ReLU-3          [128, 16, 32, 32]               0\n",
            "            Conv2d-4          [128, 32, 32, 32]           4,640\n",
            "       BatchNorm2d-5          [128, 32, 32, 32]              64\n",
            "              ReLU-6          [128, 32, 32, 32]               0\n",
            "         MaxPool2d-7          [128, 32, 16, 16]               0\n",
            "            Conv2d-8          [128, 64, 16, 16]          18,496\n",
            "       BatchNorm2d-9          [128, 64, 16, 16]             128\n",
            "             ReLU-10          [128, 64, 16, 16]               0\n",
            "        MaxPool2d-11            [128, 64, 8, 8]               0\n",
            "           Conv2d-12           [128, 128, 8, 8]          73,856\n",
            "      BatchNorm2d-13           [128, 128, 8, 8]             256\n",
            "             ReLU-14           [128, 128, 8, 8]               0\n",
            "        MaxPool2d-15           [128, 128, 4, 4]               0\n",
            "           Conv2d-16           [128, 256, 4, 4]         295,168\n",
            "      BatchNorm2d-17           [128, 256, 4, 4]             512\n",
            "             ReLU-18           [128, 256, 4, 4]               0\n",
            "           Linear-19                 [128, 128]         524,416\n",
            "      BatchNorm1d-20                 [128, 128]             256\n",
            "             ReLU-21                 [128, 128]               0\n",
            "           Linear-22                 [128, 128]          16,512\n",
            "      BatchNorm1d-23                 [128, 128]             256\n",
            "             ReLU-24                 [128, 128]               0\n",
            "           Linear-25                  [128, 10]           1,290\n",
            "================================================================\n",
            "Total params: 937,098\n",
            "Trainable params: 937,098\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.50\n",
            "Forward/backward pass size (MB): 242.76\n",
            "Params size (MB): 3.57\n",
            "Estimated Total Size (MB): 247.83\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTXc5MC8Tero"
      },
      "source": [
        "Let's check what another instantiation looks like and how many parameters it has by cycling over the list of trainable parameters of our model. Is this what you expected based on the code above? Do the dimensions match in a way that you expected?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEZhwrXEDzi2",
        "outputId": "b5c91bd2-d306-4b06-966c-01df4455f256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "cnn = VanillaCNN(input_side=input_side, hidden_width=128, n_classes=n_classes, n_additional_convs=4, use_batch_norm=False)\n",
        "params = 0\n",
        "for p in cnn.parameters():\n",
        "  print(type(p), p.shape)\n",
        "  params += np.prod(p.shape)\n",
        "print(f\"Total number of parameters: {params}, ({params*4/1024/1024:.1f} MB)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 3, 5, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 16, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 32, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 64, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 128, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 4096])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "Total number of parameters: 935594, (3.6 MB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dR2H8G_CSk2",
        "outputId": "6a9cfadd-0a01-4b9f-ab85-37cd7f22cad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cnn.state_dict().keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['first_conv.0.weight', 'first_conv.0.bias', 'additional_convs.0.0.weight', 'additional_convs.0.0.bias', 'additional_convs.1.0.weight', 'additional_convs.1.0.bias', 'additional_convs.2.0.weight', 'additional_convs.2.0.bias', 'additional_convs.3.0.weight', 'additional_convs.3.0.bias', 'first_fc.0.weight', 'first_fc.0.bias', 'second_fc.0.weight', 'second_fc.0.bias', 'third_fc.weight', 'third_fc.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkSETgPXG4wv",
        "outputId": "b7dddbc8-0f1b-456d-db5e-07bcded7bc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cnn.state_dict()['first_conv.0.weight'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhtUJ86T6YgA"
      },
      "source": [
        "Let's plot the kernels of the first convolutional layer. We should see random patterns, as we haven't trained them yet. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lkYBNOdCLSM",
        "outputId": "07f56806-4e13-4b5c-b197-74de81bd26f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "%matplotlib inline\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    plt.axis('off')\n",
        "\n",
        "def show_first_kernels(state_dict):\n",
        "  show(torchvision.utils.make_grid(state_dict['first_conv.0.weight'].cpu(), normalize=True, scale_each=True))\n",
        "show_first_kernels(cnn.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABqCAYAAAAfgIIWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALvUlEQVR4nO3de5iN5RrH8Xs5lzJoqDBhTIVyjqS0iZxVlMN2KKeGdCCDcsqpYopQJqIh5VREGGpPptBBxCQ5q0wbqZw3bUVZ+w9cV9f1/Bbvmj3Xs//Y38+fv/VcM/esWXN7L+/z3k8oHA4bAMCPXP/rAgDg/wlNFwA8oukCgEc0XQDwiKYLAB7ludiLoVCIrQ0AEKVwOByK9BpXugDgEU0XADyi6QKARzRdAPCIpgsAHtF0AcAjmi4AeETTBQCPaLoA4BFNFwA8oukCgEcXnb0QrUPbSjrZi6NelGtj6uyW+asb3pH5vDdWOVndXMWCF2dm3UsnynzO7QkyP7uqlZOtq11Wrn1q+9syT9/eMWB1Zu1jz8j8vZhGMk9+w63PzGzrJ9fJvEnxtU7WukdywOrOabTtZ5nfnPm+k/1ZqadcG9OhiMzzz54n8yHV6geszqxZzwdlvqbyepkXHv6czJdluO9tzNRKcm38lK0Bqzun05EyTvZRR/2nGLfoSpnfOqezzK9OfErmQ87qz5aSdOaszF8ZWUXmrXY3dbJaC/VncPoS93NiZrajxfKA1Z1zNnWykw1cU1yu7blA/w2G+/SV+exTW5xs1ERdd3ZwpQsAHtF0AcAjmi4AeETTBQCPcvRGWkanTk52x48vy7Vdtuv/aE8pf1zmv/e4L/uFndd1axOZf1xL/9szeH2sk920boVc+9g4/Z/16QFrMzNbk/y1zDv/62OZP77ieZnPrPOCzE93uz+KarTKI6rLPE+Kmz/f55RcO37eSJkX7ODe6ItW336DZJ5UobnMR9UcJ/O8Eys42Sf3TtDfdIq+0RnJgC/fdbL9TSfKtSdXb5L5jAqrZX5dYoQbPlMbBivOzJrH65uRMUNvlPmp2o87Wae3Jsm1DY7rm11VA9Z2QYHYL5xseavDcm3WJv23+XlyGZnPvF7dXM0XtLRL4koXADyi6QKARzRdAPCIpgsAHtF0AcCjHN298NvO152scTl9t7vZH3fIfM1pfYd448p/i/T6wLWZmX2avFjmx9L2yfzphu5ujDGJ+nHKEl31HV9b+2aw4szs2KsfyLzukbYyv7/uQzKfknaXzH+Zerf4IsFqu6DtFwVlvrro005WvE4fubZ4a/1oeNMd+hFjyzM4WHFmVrq8rm9/P/147L3X6l0NCZlxTvZtzf6B67iYzl9ucLLNO/Tj7w+u1jtA8h3R79WWBPE7jlKN2v1kfuh0N5l/F3IfSe758yq5dvaq27Nd1199UGizk/WeP0aujU11H+s1M8t6W38+D3691A13Bq/tUrjSBQCPaLoA4BFNFwA8oukCgEc0XQDwKEd3L2y7wR1mnD7AHTZsZnbnwVkyH7FL7144kD/Cc+9RKGIPyPxQKT2AfPkP7nP5b1TWuxTevapi9gs7r3GZejJ/Pdc9Mv/1kY0yn1oyXuaF/vzvBzFXrazfw40x7oyNFS/ptQtjL5d5weHuvINoLXvggMw7TtazB+I2uXMDzMwKDHGHmBfbMj/7hf3FvlfcHRYvDdbD8Ze10TNHEn79XuZ7Junf8XFzd2NEcmXmLTLf2neJzJc85H7eKrUZJdemTtOzS6KVUuJDJxs/8mq5dn+Wrjs09xuZxw8+5GQN0v8RRXUXx5UuAHhE0wUAj2i6AOARTRcAPKLpAoBHObp7IfnkCCdLz9dYrl3VSk++v/l2dweEmVlKC/e56tbTBgYvzsxaNToh88+L6efY+9Ub4GSZw/R8hD0Tpsg80/TPo+zokFvmS8voifj9d7vzDszMKjUvKfPP1t0ZuJZIuizQOw92LHJPt8hfW78n6c+Plfmm7xpE+K41AtVmZtZymN4B0XtYOZmXmldHf51u7s9zVz69G+PJzTMCVndOg/3uwIsBg/RR68c/0qdpvNypq8wb59KniXQIWJuZ2eQVz8h80Gp97Pv0d0Y72Y07E+TaUtV/0t/0Qz0zI5I+w4s4WWL+03LtgKmZMn9mVmuZD86TFFUt0eJKFwA8oukCgEc0XQDwiKYLAB7RdAHAo1A4HI78YigU+UUAgBQOh0ORXuNKFwA8oukCgEc0XQDwiKYLAB7RdAHAI5ouAHhE0wUAj2i6AOARTRcAPKLpAoBHOTrEfFeXdU5W46qZcm1c0WUyL5a5RuYLW45w13Z5K3hxZrZ82lmZH238mcxrLhnvZIXjSsi1E4Yly3zsFj2cWin5Q12Zd2w+W+afxqTIvHLhK2Tee+kT7trchQNWd86gcfp492FV/nSyp7o2kWsPZ1WS+ZnR6TJfMHJpwOrMrPFmGQ9ZoYfptx2oB6dPyvuYk6WlrZdrf9nivq8X0y6vO2S+dM9mcu2yF/Sg/pEt9QD7fhl6EP4+eydgdWbvn9wi8/FH9XH1A+N+dLLpP+lh/4XO3CDz1LgzAas7Z3939315KU0fk34iSR/7PnRzL5lvqFrRyVr313/f2cGVLgB4RNMFAI9ougDgEU0XADyi6QKARzm6e2HSyhZOVia0Ua49UlXvJMgaPVfmubfPEml0uxcqNuoh8xar3eOczcyOzT/kZIfXuUdzm5n9c3o7mY/tFrA4Mxtbv5XM5xWJk3l6TX2MfY967nH1ZmZtEu8LXkwEeeZcJfNx4u5uxuaH5Nr+PavLvMsf+ljxBRZ890L8cPd4czOzpHtGyPyHv+tj1Se0d4/nPpmaJdcG3xdwTqFq7p33jF36T3Hujd/JfHSTm2W+O0v//Vymv4xUsHRL/TV61ZP5C0kNnax64cvl2lsWDpB5qumj4yPZmz/WyeLrvynXNh34tsxHJRaVecypPVHVEi2udAHAI5ouAHhE0wUAj2i6AOARTRcAPMrR3Qv7Chx0sm359N3h99KflHmxGvoO9t66h7Nf2HkDU1fKvFzvsTJv2fxVJ2u6op5c2/0nPTchGsu/3ynztCf0PIF+axfL/O6Zt8n8monujpGdqQGLO2/+gXoyL1r3KydrP2e7XFu/Qw2Zx7bJjK4Y4a6UW2XeumaCzHddVkvmV6x0d6nUT16kv2m3vsGKO6/38KpOViZJzyhZ/LQ7z8TM7Pcxn8r83YruHAQzM4ti98Kcl9vLvMqoAzLPvdL9XM2ML6TLKKt34kTranPnQ6QlrpVrM8rr3S+Fxs+R+dB7+jiZO4Ul+7jSBQCPaLoA4BFNFwA8oukCgEc0XQDwKEd3Lyx99FEnm3i6oFz7t7ruSQNmZtWu+EjmGdOiGGIQQZXbwjJvlnJa5mfGuLsDHi6vb/c/t2iTzJfpR82lar31PIor79YnR8Qn6Z+nQC999/l4OTVZf2+g2i44OF3v0kh51N0ZUiDxiFx77Fl9N3lehGsAfeaDVm9TR5m/9sw3Mn/gq10yb3bGnY8wv7Q+rcEsut0LR4e77+G+faXk2lc+0zMMCurxGvbYic/1C+l6JoXSdvpzMr+pkN698O0s9/eZHKvniBzqpneXmD68JaLEKm6vadtOvyknhr0o848Tfpd554QJIu0QuLZL4UoXADyi6QKARzRdAPCIpgsAHtF0AcCjHN29MOPaQU4W+8S3cu2GLv1lXra5nnw/Y0GiG07uF7w4M8uzRU+Qv+nZX2T+W9YXTtZusZ4b0KjYiKhqUfZU13MqtufXz4inprwm84Jzy8r8yGl1p14/Ix9Ju8S8Mk9P7+Jkp+5Il2tja9yg81X6Dr5VDlSamZl16Ko/V1VnF5d5xtnCMv8jy93tUKvqUbm2SsDaLmjYrJeTrbsmt1y7tmaGzFe/r08qmf+nntWgJztoRya6pzKYmd1ZQc91ODVivZPVGqpnWuxor3cMROuRh93ZLSWWfSjXVix2jcxv/dH9PZiZnd3b3cnSoqjtUrjSBQCPaLoA4BFNFwA8oukCgEehcFg/SmpmFgqFIr8IAJDC4XAo0mtc6QKARzRdAPCIpgsAHtF0AcAjmi4AeETTBQCPaLoA4BFNFwA8oukCgEc0XQDwiKYLAB5ddPYCACBncaULAB7RdAHAI5ouAHhE0wUAj2i6AOARTRcAPPoPbOiZhpd4VnQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlAnk6SRT8zR"
      },
      "source": [
        "Let's check that a randomly initialized model has expected loss value and accuracy. \n",
        "\n",
        "This also shows how to move weights and data onto the GPU by using the `to` function of `Module`s and `Tensor`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_524xl_7G31W",
        "outputId": "9f5443cb-7cfe-44d7-a541-f14d6f05ba2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def ncorrect(scores, y):\n",
        "  y_hat = torch.argmax(scores, 1)\n",
        "  return (y_hat==y).sum()\n",
        "\n",
        "def accuracy(scores, y):\n",
        "  correct = ncorrect(scores, y)\n",
        "  return correct.true_divide(y.shape[0])\n",
        "  \n",
        "def test_model(device, cnn, dl):\n",
        "  with torch.no_grad():\n",
        "    total_loss = 0\n",
        "    n_samples = 0\n",
        "    n_correct = 0\n",
        "    for data in dl:\n",
        "      images = data[0].to(device) # move images to GPU\n",
        "      labels = data[1].to(device) # move labels to GPU\n",
        "      scores = cnn.forward(images)\n",
        "      loss = F.cross_entropy(scores, labels)\n",
        "      total_loss += loss.item() * data[0].shape[0]\n",
        "      n_samples += data[0].shape[0]\n",
        "      n_correct += ncorrect(scores, labels).item()\n",
        "    return total_loss/n_samples, n_samples, n_correct\n",
        "\n",
        "start=timer()\n",
        "loss, n_samples, n_correct = test_model(device, cnn.to(device), test_dl) # move model to GPU\n",
        "print(f\"Loss {loss}, Accuracy {n_correct/n_samples}\")\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 2.3036390731811522, Accuracy 0.1\n",
            "Elapsed time (s): 1.9849860799999988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZK3vVROUOQ1"
      },
      "source": [
        "Then we define our usual function to train a model. \n",
        "\n",
        "Note the use of `nn.train()` and `nn.eval()` to tell the model in which phase we are: we have to start to include these calls since we are using BatchNorm, which behaves differently between training and test time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iskt1fK0ELgM"
      },
      "source": [
        "def train_loop(device, input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm,\n",
        "               train_dl, epochs, partial_opt, \n",
        "               valid_dl=None, verbose=False, print_every=5):\n",
        "  best_valid_acc = 0\n",
        "  best_params = []\n",
        "  best_epoch = -1\n",
        "\n",
        "  nn = VanillaCNN(input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm)\n",
        "  nn.to(device)\n",
        "\n",
        "  # We \"complete\" the partial function by calling it and specifying the missing parameters\n",
        "  opt = partial_opt(nn.parameters())\n",
        "\n",
        "  for e in range(epochs):\n",
        "    #if epochs-e == 10:\n",
        "    #  for param_group in opt.param_groups:\n",
        "    #    param_group['lr'] /= 10\n",
        "    #train\n",
        "    train_loss = 0\n",
        "    train_samples = 0\n",
        "    train_acc = 0\n",
        "    nn.train() # put the model in training mode\n",
        "    for train_data in train_dl:\n",
        "      train_images = train_data[0].to(device)\n",
        "      train_labels = train_data[1].to(device)\n",
        "      scores = nn.forward(train_images)\n",
        "      loss = F.cross_entropy(scores, train_labels)\n",
        "      train_loss += loss.item() * train_data[0].shape[0]\n",
        "      train_samples += train_data[0].shape[0]\n",
        "      train_acc += ncorrect(scores, train_labels).item()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    train_acc /= train_samples\n",
        "    train_loss /= train_samples\n",
        "    \n",
        "    # validation\n",
        "    nn.eval() # put the model in evaluation mode\n",
        "    with torch.no_grad():\n",
        "      valid_loss = 0\n",
        "      valid_samples = 0\n",
        "      valid_acc = 0\n",
        "      if valid_dl is not None:\n",
        "        for valid_data in valid_dl:\n",
        "          valid_images = valid_data[0].to(device)\n",
        "          valid_labels = valid_data[1].to(device)\n",
        "          valid_scores = nn.forward(valid_images)\n",
        "          valid_loss += F.cross_entropy(valid_scores, valid_labels).item() * valid_data[0].shape[0]\n",
        "          valid_samples += valid_data[0].shape[0]\n",
        "          valid_acc += ncorrect(valid_scores, valid_labels).item()\n",
        "        valid_acc /= valid_samples\n",
        "        valid_loss /= valid_samples\n",
        "      \n",
        "      if valid_dl is None or valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc if valid_dl is not None else 0\n",
        "        best_params = copy.deepcopy(nn.state_dict())\n",
        "        best_epoch = e\n",
        "        \n",
        "      \n",
        "    if verbose and e % print_every == 0:\n",
        "      print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if valid_dl is None else f\" - valid loss {valid_loss:.3f} - valid acc {valid_acc:.3f}\"))\n",
        "  \n",
        "  if verbose and valid_dl is not None:\n",
        "    print(f\"Best epoch {best_epoch}, best acc {best_valid_acc}\")\n",
        "\n",
        "  return best_valid_acc, best_params, best_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So2fjoCcUalq"
      },
      "source": [
        "Let's compare a not too deep architecture with and without BN. \n",
        "\n",
        "Let's also make sure we can perfectly fit a small training set (i.e. reach train accuracy 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBnh5zKH5ql7",
        "outputId": "828c1523-77c3-46b0-eb38-18522701c5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "start = timer()\n",
        "lr=1e-3\n",
        "hidden_width=128\n",
        "n_additional_convs=3\n",
        "use_batch_norm=False\n",
        "p_opt = partial(torch.optim.Adam, lr=lr)\n",
        "\n",
        "_, best_params, best_epoch = train_loop(device, input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm,\n",
        "           train_dl=small_actual_train_dl, epochs=80, partial_opt=p_opt, \n",
        "           valid_dl=small_valid_dl, verbose=True)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 2.294 - train acc 0.136 - valid loss 2.359 - valid acc 0.060\n",
            "Epoch 5: train loss 1.993 - train acc 0.302 - valid loss 2.102 - valid acc 0.220\n",
            "Epoch 10: train loss 1.724 - train acc 0.382 - valid loss 2.069 - valid acc 0.200\n",
            "Epoch 15: train loss 1.501 - train acc 0.464 - valid loss 2.048 - valid acc 0.200\n",
            "Epoch 20: train loss 1.183 - train acc 0.566 - valid loss 1.895 - valid acc 0.280\n",
            "Epoch 25: train loss 0.836 - train acc 0.736 - valid loss 2.155 - valid acc 0.260\n",
            "Epoch 30: train loss 0.568 - train acc 0.806 - valid loss 2.450 - valid acc 0.300\n",
            "Epoch 35: train loss 0.200 - train acc 0.946 - valid loss 3.379 - valid acc 0.320\n",
            "Epoch 40: train loss 0.065 - train acc 0.988 - valid loss 4.203 - valid acc 0.290\n",
            "Epoch 45: train loss 0.020 - train acc 1.000 - valid loss 5.219 - valid acc 0.300\n",
            "Epoch 50: train loss 0.004 - train acc 1.000 - valid loss 5.867 - valid acc 0.280\n",
            "Epoch 55: train loss 0.002 - train acc 1.000 - valid loss 6.123 - valid acc 0.280\n",
            "Epoch 60: train loss 0.001 - train acc 1.000 - valid loss 6.341 - valid acc 0.300\n",
            "Epoch 65: train loss 0.001 - train acc 1.000 - valid loss 6.509 - valid acc 0.290\n",
            "Epoch 70: train loss 0.001 - train acc 1.000 - valid loss 6.649 - valid acc 0.290\n",
            "Epoch 75: train loss 0.001 - train acc 1.000 - valid loss 6.774 - valid acc 0.290\n",
            "Best epoch 22, best acc 0.37\n",
            "Elapsed time (s): 10.667273455999975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1frTAK_KGG_",
        "outputId": "8019f7d2-2306-4bb6-a784-add7ee9042bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "start = timer()\n",
        "lr=1e-3\n",
        "hidden_width=128\n",
        "n_additional_convs=3\n",
        "use_batch_norm=True\n",
        "p_opt = partial(torch.optim.Adam, lr=lr)\n",
        "\n",
        "_, best_params, best_epoch = train_loop(device, input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm,\n",
        "           train_dl=small_actual_train_dl, epochs=25, partial_opt=p_opt, \n",
        "           valid_dl=small_valid_dl, verbose=True)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 2.156 - train acc 0.210 - valid loss 2.311 - valid acc 0.100\n",
            "Epoch 5: train loss 0.559 - train acc 0.986 - valid loss 2.514 - valid acc 0.100\n",
            "Epoch 10: train loss 0.107 - train acc 1.000 - valid loss 1.997 - valid acc 0.270\n",
            "Epoch 15: train loss 0.039 - train acc 1.000 - valid loss 1.928 - valid acc 0.390\n",
            "Epoch 20: train loss 0.021 - train acc 1.000 - valid loss 1.984 - valid acc 0.360\n",
            "Best epoch 15, best acc 0.39\n",
            "Elapsed time (s): 3.704436717999897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySa8QOgAUpxQ"
      },
      "source": [
        "Let's see if the difference holds when we train on the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRff3L4IKjow",
        "outputId": "1ec8f468-3dd1-438f-ffc3-bad931c533d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "start = timer()\n",
        "lr=1e-3\n",
        "hidden_width=128\n",
        "n_additional_convs=3\n",
        "use_batch_norm=False\n",
        "p_opt = partial(torch.optim.Adam, lr=lr)\n",
        "\n",
        "_, best_params, best_epoch = train_loop(device, input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm,\n",
        "           train_dl=actual_train_dl, epochs=20, partial_opt=p_opt, \n",
        "           valid_dl=valid_dl, verbose=True, print_every=1)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 1.670 - train acc 0.384 - valid loss 1.390 - valid acc 0.497\n",
            "Epoch 1: train loss 1.268 - train acc 0.541 - valid loss 1.158 - valid acc 0.595\n",
            "Epoch 2: train loss 1.043 - train acc 0.627 - valid loss 0.993 - valid acc 0.655\n",
            "Epoch 3: train loss 0.893 - train acc 0.686 - valid loss 0.923 - valid acc 0.684\n",
            "Epoch 4: train loss 0.778 - train acc 0.730 - valid loss 0.918 - valid acc 0.690\n",
            "Epoch 5: train loss 0.685 - train acc 0.763 - valid loss 0.894 - valid acc 0.704\n",
            "Epoch 6: train loss 0.605 - train acc 0.789 - valid loss 0.849 - valid acc 0.720\n",
            "Epoch 7: train loss 0.548 - train acc 0.810 - valid loss 0.901 - valid acc 0.710\n",
            "Epoch 8: train loss 0.489 - train acc 0.829 - valid loss 0.942 - valid acc 0.712\n",
            "Epoch 9: train loss 0.446 - train acc 0.844 - valid loss 0.985 - valid acc 0.717\n",
            "Epoch 10: train loss 0.394 - train acc 0.864 - valid loss 1.113 - valid acc 0.699\n",
            "Epoch 11: train loss 0.355 - train acc 0.872 - valid loss 1.124 - valid acc 0.702\n",
            "Epoch 12: train loss 0.327 - train acc 0.884 - valid loss 1.302 - valid acc 0.690\n",
            "Epoch 13: train loss 0.305 - train acc 0.892 - valid loss 1.297 - valid acc 0.692\n",
            "Epoch 14: train loss 0.269 - train acc 0.903 - valid loss 1.427 - valid acc 0.686\n",
            "Epoch 15: train loss 0.237 - train acc 0.915 - valid loss 1.434 - valid acc 0.683\n",
            "Epoch 16: train loss 0.222 - train acc 0.920 - valid loss 1.428 - valid acc 0.683\n",
            "Epoch 17: train loss 0.206 - train acc 0.926 - valid loss 1.580 - valid acc 0.670\n",
            "Epoch 18: train loss 0.174 - train acc 0.939 - valid loss 1.701 - valid acc 0.688\n",
            "Epoch 19: train loss 0.153 - train acc 0.945 - valid loss 1.638 - valid acc 0.686\n",
            "Best epoch 6, best acc 0.72\n",
            "Elapsed time (s): 210.4187179239998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OikdqD6Gjs3",
        "outputId": "f6d29c34-dd29-4769-a998-407354d2a3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "show_first_kernels(best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhxHUE8u0i5F",
        "outputId": "c19d58e4-8cf9-4440-ba01-b02855549319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "start = timer()\n",
        "lr=1e-3\n",
        "hidden_width=128\n",
        "n_additional_convs=3\n",
        "use_batch_norm=True\n",
        "p_opt = partial(torch.optim.Adam, lr=lr)\n",
        "\n",
        "_, best_params, best_epoch = train_loop(device, input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm,\n",
        "           train_dl=actual_train_dl, epochs=20, partial_opt=p_opt, \n",
        "           valid_dl=valid_dl, verbose=True, print_every=1)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 1.152 - train acc 0.593 - valid loss 0.941 - valid acc 0.675\n",
            "Epoch 1: train loss 0.754 - train acc 0.734 - valid loss 0.831 - valid acc 0.716\n",
            "Epoch 2: train loss 0.579 - train acc 0.799 - valid loss 0.826 - valid acc 0.725\n",
            "Epoch 3: train loss 0.451 - train acc 0.845 - valid loss 0.854 - valid acc 0.728\n",
            "Epoch 4: train loss 0.347 - train acc 0.881 - valid loss 1.049 - valid acc 0.696\n",
            "Epoch 5: train loss 0.275 - train acc 0.906 - valid loss 1.011 - valid acc 0.716\n",
            "Epoch 6: train loss 0.208 - train acc 0.927 - valid loss 1.065 - valid acc 0.719\n",
            "Epoch 7: train loss 0.160 - train acc 0.945 - valid loss 1.111 - valid acc 0.728\n",
            "Epoch 8: train loss 0.126 - train acc 0.957 - valid loss 1.103 - valid acc 0.742\n",
            "Epoch 9: train loss 0.103 - train acc 0.964 - valid loss 1.245 - valid acc 0.733\n",
            "Epoch 10: train loss 0.089 - train acc 0.969 - valid loss 1.389 - valid acc 0.724\n",
            "Epoch 11: train loss 0.075 - train acc 0.974 - valid loss 1.462 - valid acc 0.717\n",
            "Epoch 12: train loss 0.061 - train acc 0.978 - valid loss 1.284 - valid acc 0.744\n",
            "Epoch 13: train loss 0.060 - train acc 0.979 - valid loss 1.506 - valid acc 0.715\n",
            "Epoch 14: train loss 0.062 - train acc 0.979 - valid loss 1.345 - valid acc 0.741\n",
            "Epoch 15: train loss 0.058 - train acc 0.979 - valid loss 1.316 - valid acc 0.748\n",
            "Epoch 16: train loss 0.055 - train acc 0.981 - valid loss 1.369 - valid acc 0.748\n",
            "Epoch 17: train loss 0.046 - train acc 0.984 - valid loss 1.397 - valid acc 0.745\n",
            "Epoch 18: train loss 0.037 - train acc 0.987 - valid loss 1.403 - valid acc 0.758\n",
            "Epoch 19: train loss 0.038 - train acc 0.986 - valid loss 1.554 - valid acc 0.745\n",
            "Best epoch 18, best acc 0.7576\n",
            "Elapsed time (s): 220.98080373099992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLk1QPb9GpEv",
        "outputId": "f1353d17-3da7-4701-afa4-e101f6b77fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "show_first_kernels(best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X79rgnsLBY_y"
      },
      "source": [
        "Let's train the batch-norm model on the full training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI8lOp_jA-Gy",
        "outputId": "24e044f6-bb6b-4407-f93a-76e59aebd026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "start = timer()\n",
        "lr=1e-3\n",
        "hidden_width=128\n",
        "n_additional_convs=3\n",
        "use_batch_norm=True\n",
        "p_opt = partial(torch.optim.Adam, lr=lr)\n",
        "\n",
        "_, best_params, _ = train_loop(device, input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm,\n",
        "           train_dl=train_dl, epochs=best_epoch, partial_opt=p_opt, \n",
        "           valid_dl=None, verbose=True, print_every=1)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 1.131 - train acc 0.600\n",
            "Epoch 1: train loss 0.739 - train acc 0.740\n",
            "Epoch 2: train loss 0.572 - train acc 0.800\n",
            "Epoch 3: train loss 0.440 - train acc 0.849\n",
            "Epoch 4: train loss 0.344 - train acc 0.882\n",
            "Epoch 5: train loss 0.263 - train acc 0.910\n",
            "Epoch 6: train loss 0.210 - train acc 0.928\n",
            "Epoch 7: train loss 0.164 - train acc 0.944\n",
            "Epoch 8: train loss 0.130 - train acc 0.955\n",
            "Epoch 9: train loss 0.105 - train acc 0.964\n",
            "Epoch 10: train loss 0.080 - train acc 0.973\n",
            "Epoch 11: train loss 0.072 - train acc 0.975\n",
            "Epoch 12: train loss 0.074 - train acc 0.974\n",
            "Epoch 13: train loss 0.068 - train acc 0.976\n",
            "Epoch 14: train loss 0.058 - train acc 0.980\n",
            "Epoch 15: train loss 0.051 - train acc 0.982\n",
            "Epoch 16: train loss 0.045 - train acc 0.984\n",
            "Epoch 17: train loss 0.045 - train acc 0.984\n",
            "Elapsed time (s): 198.14603398999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8T4DzheH0cB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99djaieJBmGB",
        "outputId": "50bac221-6353-4f44-9dda-550c70ee012d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "start=timer()\n",
        "best_cnn = VanillaCNN(input_side, hidden_width, n_classes, n_additional_convs, use_batch_norm)\n",
        "best_cnn.load_state_dict(best_params)\n",
        "best_cnn.eval()\n",
        "loss, n_samples, n_correct = test_model(device, best_cnn.to(device), test_dl) # move model to GPU\n",
        "print(f\"Loss {loss}, Accuracy {n_correct/n_samples}\")\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 1.3282168466567994, Accuracy 0.7656\n",
            "Elapsed time (s): 1.9524092410001685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWvI2nrbZb3k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}